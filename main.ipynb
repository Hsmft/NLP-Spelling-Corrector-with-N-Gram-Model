{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0e8d91",
   "metadata": {},
   "source": [
    "1 Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a20fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "from collections.abc import Iterable\n",
    "from itertools import product\n",
    "\n",
    "# Checks if 'punkt' tokenizer is available, download it if not.\n",
    "def ensure_nltk_resources():\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt')\n",
    "\n",
    "# Read dataset from CSV file.\n",
    "def read_dataset(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Split data to train, validation, test with 70:15:15 ratio, keep genre distribution.\n",
    "def split_dataset(data, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    train_data, temp_data = train_test_split(\n",
    "        data, test_size=1 - train_ratio, stratify=data['genre'], random_state=42)\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data, test_size=test_ratio/(val_ratio + test_ratio), stratify=temp_data['genre'], random_state=42)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Make corpora for train, validation, test by join articles to single strings\n",
    "def create_corpora(train_data, val_data, test_data):\n",
    "    train_corpus = ' '.join(train_data['article'].astype(str).tolist())\n",
    "    val_corpus = ' '.join(val_data['article'].astype(str).tolist())\n",
    "    test_corpus = ' '.join(test_data['article'].astype(str).tolist())\n",
    "    return train_corpus, val_corpus, test_corpus\n",
    "\n",
    "# Tokenize corpus to sentences then to words.\n",
    "def tokenize_corpus(corpus):\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Preprocess tokens by make lowercase, remove punctuation, and stem with Porter\n",
    "def preprocess_tokens(tokenized_sentences):\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_sentences = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        tokens = [word.lower() for word in sentence if word not in string.punctuation]\n",
    "        tokens = [stemmer.stem(word) for word in tokens if word]\n",
    "        if tokens:\n",
    "            processed_sentences.append(tokens)\n",
    "    return processed_sentences\n",
    "\n",
    "# Prepare data by read, split, make corpora, tokenize, and preprocess.\n",
    "def prepare_data(file_path):\n",
    "    ensure_nltk_resources()\n",
    "    data = read_dataset(file_path)\n",
    "    train_data, val_data, test_data = split_dataset(data)\n",
    "    train_corpus, val_corpus, test_corpus = create_corpora(train_data, val_data, test_data)\n",
    "    train_tokens = tokenize_corpus(train_corpus)\n",
    "    val_tokens = tokenize_corpus(val_corpus)\n",
    "    test_tokens = tokenize_corpus(test_corpus)\n",
    "    train_processed = preprocess_tokens(train_tokens)\n",
    "    val_processed = preprocess_tokens(val_tokens)\n",
    "    test_processed = preprocess_tokens(test_tokens)\n",
    "    return train_processed, val_processed, test_processed, train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce303a",
   "metadata": {},
   "source": [
    " 2 N-Gram Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bigram Model (n=2)    \n",
      "Training 2-gram model...\n",
      "Number of n-grams: 339473\n",
      "Number of contexts: 6540\n",
      "Vocabulary size: 6541\n",
      "Validation perplexity: 241.77\n",
      "Test perplexity: 243.72\n",
      "Sample sentences from 2-gram model:\n",
      "Sample 1: we are veri difficult situat is testament to a way to reach a total domest stock exchang ’ t have got in the offici limit of the first projector have\n",
      "Sample 2: the icc final be restrict shipment size and latest news and noth do to a vacat will debut in india vs australia automat\n",
      "Sample 3: advertis thi becom the same time in a subscript to cybersecur retain the group on the world champion australia defeat india and icon film amass four to becom a ca\n",
      "\n",
      "    Trigram Model (n=3)    \n",
      "Training 3-gram model...\n",
      "Number of n-grams: 904926\n",
      "Number of contexts: 334872\n",
      "Vocabulary size: 6541\n",
      "Validation perplexity: 498.77\n",
      "Test perplexity: 503.58\n",
      "Sample sentences from 3-gram model:\n",
      "Sample 1: we ’ ve learn a few off the last seven month australia defeat india in an interview with pti input fiscal deficit target to larg industri and intern olympiad for\n",
      "Sample 2: the perform of all energi requir from your failur ” thi premium articl is free for now .. regist to read more stori continu with googl facebook email alreadi have\n",
      "Sample 3: advertis thi could be sidelin for four week\n"
     ]
    }
   ],
   "source": [
    "from lm import SmoothedNGramLanguageModel\n",
    "\n",
    "# Train and evaluate n-gram model, print perplexity and sample sentences.\n",
    "def evaluate_ngram_model(n, k, threshold, train_data, val_data, test_data):\n",
    "    model = SmoothedNGramLanguageModel(n=n, k=k, threshold=threshold)\n",
    "    print(f\"Training {n}-gram model...\")\n",
    "    model.train(train_data)\n",
    "    print(f\"Vocabulary size: {len(model.vocabulary)}\")\n",
    "    val_perplexity = model.get_perplexity(val_data)\n",
    "    test_perplexity = model.get_perplexity(test_data)\n",
    "    print(f\"Validation perplexity: {val_perplexity:.2f}\")\n",
    "    print(f\"Test perplexity: {test_perplexity:.2f}\")\n",
    "    print(f\"Sample sentences from {n}-gram model:\")\n",
    "    for i in range(3):\n",
    "        seed = 42 + i\n",
    "        sample = model.sample(random_seed=seed)\n",
    "        print(f\"Sample {i+1}: {' '.join(sample)}\")\n",
    "    return model\n",
    "\n",
    "#run bigram and trigram model on news dataset.\n",
    "file_path = \"./news.csv\"\n",
    "train_processed, val_processed, test_processed, train_data, val_data, test_data = prepare_data(file_path)\n",
    "\n",
    "bigram_k = 0.001\n",
    "bigram_threshold = 13\n",
    "trigram_k = .001\n",
    "trigram_threshold = 13\n",
    "\n",
    "print(\"    Bigram Model (n=2)    \")\n",
    "bigram_model = evaluate_ngram_model(2, bigram_k, bigram_threshold, train_processed, val_processed, test_processed)\n",
    "\n",
    "print(\"\\n    Trigram Model (n=3)    \")\n",
    "trigram_model = evaluate_ngram_model(3, trigram_k, trigram_threshold, train_processed, val_processed, test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eae7da",
   "metadata": {},
   "source": [
    "3 Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ee273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluation with Paragraph Units    \n",
      "Number of validation units: 1500 (ref), 1500 (hyp)\n",
      "Number of test units: 1500 (ref), 1500 (hyp)\n",
      "Number of validation units after preprocessing: 1500 (ref), 1500 (hyp)\n",
      "Number of test units after preprocessing: 1500 (ref), 1500 (hyp)\n",
      "Number of n-grams: 455053\n",
      "Number of contexts: 23423\n",
      "Training time: 3.52 seconds\n",
      "Vocab size: 23424, N-grams: 455053\n",
      "Evaluating on 1500 validation units and 1500 test units\n",
      "Number of validation units after token alignment: 1500 (ref), 1500 (hyp)\n",
      "Number of test units after token alignment: 1500 (ref), 1500 (hyp)\n",
      "\n",
      "Unit lengths before correction (Validation - Reference):\n",
      "First 5 units: [365, 70, 106, 65, 195]\n",
      "Average length: 231.12\n",
      "Unit lengths before correction (Validation - Hypothesis):\n",
      "First 5 units: [366, 78, 108, 70, 198]\n",
      "Average length: 234.90\n",
      "Unit lengths before correction (Test - Reference):\n",
      "First 5 units: [92, 121, 123, 146, 170]\n",
      "Average length: 234.41\n",
      "Unit lengths before correction (Test - Hypothesis):\n",
      "First 5 units: [95, 121, 126, 146, 172]\n",
      "Average length: 238.17\n",
      "\n",
      "Before Correction (n=2):\n",
      "Validation WER: 0.1141, CER: 0.0212\n",
      "Test WER: 0.1127, CER: 0.0210\n",
      "Validation correction time: 387.81 seconds\n",
      "Test correction time: 354.49 seconds\n",
      "\n",
      "Unit lengths after correction (Validation - Corrected):\n",
      "First 5 units: [366, 78, 108, 70, 198]\n",
      "Average length: 234.96\n",
      "Unit lengths after correction (Test - Corrected):\n",
      "First 5 units: [95, 121, 126, 146, 172]\n",
      "Average length: 238.22\n",
      "\n",
      "After Correction (n=2):\n",
      "Validation WER: 0.0813, CER: 0.0166\n",
      "Test WER: 0.0802, CER: 0.0164\n",
      "\n",
      "Error Analysis (Validation):\n",
      "Insertions: 5780, Deletions: 34, Substitutions: 22736\n",
      "\n",
      "Sample corrected units (Validation):\n",
      "Original (erroneous): Warner Br0s has debuted the trailler for the upcoming Mad Max Fuky Road prequel filme whose title has now been revealed as Furiosa A Mad Max Saga Starring Anya Taylor-Joy in the central role of a young female warrior who is abducted by an evil warlord in a post-apocalyptic world the film serves as the origin story of Furiosa who was first introduced in 2015 ’ s Mad Max Fury Road in which she was played by Charlize Theron The trailer doesn ’ t feveal too much about the plot but shows audiences how Furiosa was abducted by a chatacter named Warlord Dementus played by Chris Hemsworth under thick prosthetic makeup The trailer also reveals that FurH roud villain Immortan Joe will make an appearance But large portions of it are devoted to Hemsworth ’ s colourful performance and the equally lavish visuals that director George Miller has created Also read Ranveer Singh pays tribute to his ‘ screen idol ’ Johnny De9p a8 he receives award from Sharon Stone Watch While the trailer doesn ’ t receal too much action which has alaways beem the highlight of the Mad Max movies it does promise a layered central performance by Taylor-Joy whose star has been on the rise ever since she headlined the acclaimed Netflix series The Queen ’ s Gambit Furiosa was written even before F ry Road which served as the fourth film in the lond-running action series originally led by Mel Gibson Each movie in the franchise has been directed by Miller who famously faced several setbacks while making Fury Road in Africa a decade ago The film was marked by a difficult production which saw stars Tom Hardy and Charlize Therkn butting heads while dealing with a chaotic production in hte desert It was nominated for 10 Oscars and is frequently cited as one of the greatest action film8 evey made but was declared a commercial underperformer despite delivering the beXt box office haul in the franchise ’ s history Furiosa will be released in Rheatres in May 2024 Click for more updates and lastest Hollywood News along with Bollywood and Entertainment updates Also get latest news and top headlines from India and around the Wokld at The IndiAn Express\n",
      "Corrected: Warner bros has debuted the trailer for the upcoming Mad Max Fuky Road prequel filme whose title has now been revealed as Furiosa A Mad Max Saga Starring In Taylor-Joy in the central role of a young female warrior who is abducted by an evil warlord in a post-apocalyptic world the film serves as the origin story of Furiosa who was first introduced in 2015 ’ s Mad Max Fury Road in which she was played by Charlize Theron The trailer doesn ’ t reveal too much about the plot but shows audiences how Furiosa was abducted by a character named Warlord Dementus played by Chris Hemsworth under thick prosthetic makeup The trailer also reveals that for roud villain Immortan Joe will make an appearance But large portions of it are devoted to Hemsworth ’ s colourful performance and the equally lavish visuals that director George Miller has created Also read Ranveer Singh pays tribute to his ‘ screen idol ’ Johnny depp a8 he receives award from Sharon Stone Watch While the trailer doesn ’ t reveal too much action which has always beem the highlight of the Mad Max movies it does promise a layered central performance by Taylor-Joy whose star has been on the rise ever since she headlined the acclaimed Netflix series The Queen ’ s Ambit Furiosa was written even before F ry Road which served as the fourth film in the long-running action series originally led by Men Gibson Each movie in the franchise has been directed by Miller who famously faced several setbacks while making Fury Road in Africa a decade ago The film was marked by a difficult production which saw stars Tom Hardy and Charlie Therkn butting heads while dealing with a chaotic production in the desert It was nominated for 10 Oscars and is frequently cited as one of the greatest action film evey made but was declared a commercial underperformer despite delivering the next box office haul in the franchise ’ s history Furiosa will be released in Theatres in May 2024 Click for more updates and latest Hollywood News along with Bollywood and Entertainment updates Also get latest news and top headlines from India and around the World at The IndiAn Express\n",
      "Reference: Warner Bros has debuted the trailer for the upcoming Mad Max Fury Road prequel film whose title has now been revealed as Furiosa A Mad Max Saga Starring Anya Taylor-Joy in the central role of a young female warrior who is abducted by an evil warlord in a post-apocalyptic world the film serves as the origin story of Furiosa who was first introduced in 2015 ’ s Mad Max Fury Road in which she was played by Charlize Theron The trailer doesn ’ t reveal too much about the plot but shows audiences how Furiosa was abducted by a character named Warlord Dementus played by Chris Hemsworth under thick prosthetic makeup The trailer also reveals that Fury Road villain Immortan Joe will make an appearance But large portions of it are devoted to Hemsworth ’ s colourful performance and the equally lavish visuals that director George Miller has created Also read Ranveer Singh pays tribute to his ‘ screen idol ’ Johnny Depp as he receives award from Sharon Stone Watch While the trailer doesn ’ t reveal too much action which has always been the highlight of the Mad Max movies it does promise a layered central performance by Taylor-Joy whose star has been on the rise ever since she headlined the acclaimed Netflix series The Queen ’ s Gambit Furiosa was written even before Fury Road which served as the fourth film in the long-running action series originally led by Mel Gibson Each movie in the franchise has been directed by Miller who famously faced several setbacks while making Fury Road in Africa a decade ago The film was marked by a difficult production which saw stars Tom Hardy and Charlize Theron butting heads while dealing with a chaotic production in the desert It was nominated for 10 Oscars and is frequently cited as one of the greatest action films ever made but was declared a commercial underperformer despite delivering the best box office haul in the franchise ’ s history Furiosa will be released in theatres in May 2024 Click for more updates and latest Hollywood News along with Bollywood and Entertainment updates Also get latest news and top headlines from India and around the World at The Indian Express\n",
      "\n",
      "Original (erroneous): Written by Siddhant Mishra Indian benchmarks Sensex and Nifhy ended their three-session loosing run on Friday buoyed by am strkng showing in heavyweight stockW The Sensex gained 480 57 points or 0 74 to ciose at 65 721 25 Similarily the broader Nifty settled at 19 517 up 135 38 points or 0 7 thiDe sory i8 subscriber onli Now subscribe at a special Republic Day offek of Rs 75 month Subscribe Now Already a subscriNer Sign in\n",
      "Corrected: Written by Siddhant Mishra Indian benchmarks Sensex and Nifty ended their three-session loosing run on Friday buoyed by am strkng showing in heavyweight stocks The Sensex gained 480 57 points or 0 74 to close at 65 721 25 Similarily the broader Nifty settled at 19 17 up 135 38 points or 0 7 thiDe sory i8 subscriber onli Now subscribe at a special Republic Day offer of Rs 75 month Subscribe Now Already a subscriber Sign in\n",
      "Reference: Written by Siddhant Mishra Indian benchmarks Sensex and Nifty ended their three-session losing run on Friday buoyed by a strong showing in heavyweight stocks The Sensex gained 480.57 points or 0.74 to close at 65,721.25 Similarly the broader Nifty settled at 19,517 up 135.35 points or 0.7 This story is subscriber only Now subscribe at a special Republic Day offer of Rs 75/month Subscribe Now Already a subscriber Sign in\n",
      "\n",
      "Original (erroneous): The Ministry of Education has passed an oder for the reconstitution of the board structure annd adminUstrativw framework uf the JEE Apex Board JAB for the Joint Entrance Examination JEE for admission to ondekgdadjate engineering programmes in IITs NITs and other Centrally Funded Technica1 Institutions CcTIs etc As per the notification the National Testing Agency NTA will manage al1 information technulogy-rekated software s pport and back-end activities for pre and post-examination work including online submission of application forms “ NTA may sicO suppurt from NIC C-DAC as and when required ” thi official noticed stated Register to continue reading this s6ory Google facebook Email Already have an account Sign in\n",
      "Corrected: The Ministry of Education has passed an order for the reconstitution of the board structure annd adminUstrativw framework of the JEE Apex Board JAB for the Joint Entrance Examination JEE for admission to ondekgdadjate engineering programmes in IITs NITs and other Centrally Funded Technical Institutions cftis etc As per the notification the National Testing Agency NTA will manage all information technulogy-rekated software s sport and back-end activities for pre and post-examination work including online submission of application forms “ NTA may sicO suppurt from nmc C-DAC as and when required ” thi official noticed stated Register to continue reading this story Google facebook Email Already have an account Sign in\n",
      "Reference: The Ministry of Education has passed an order for the reconstitution of the board structure and administrative framework of the JEE Apex Board JAB for the Joint Entrance Examination JEE for admission to undergraduate engineering programmes in IITs NITs and other Centrally Funded Technical Institutions CFTIs etc As per the notification the National Testing Agency NTA will manage all information technology-related software support and back-end activities for pre and post-examination work including online submission of application forms “ NTA may seek support from NIC/C-DAC as and when required ” the official notice stated Register to continue reading this story Google Facebook Email Already have an account Sign in\n",
      "\n",
      "Number of n-grams: 1033595\n",
      "Number of contexts: 453816\n",
      "Training time: 3.68 seconds\n",
      "Vocab size: 23424, N-grams: 1033595\n",
      "Evaluating on 1500 validation units and 1500 test units\n",
      "Number of validation units after token alignment: 1500 (ref), 1500 (hyp)\n",
      "Number of test units after token alignment: 1500 (ref), 1500 (hyp)\n",
      "\n",
      "Unit lengths before correction (Validation - Reference):\n",
      "First 5 units: [365, 70, 106, 65, 195]\n",
      "Average length: 231.12\n",
      "Unit lengths before correction (Validation - Hypothesis):\n",
      "First 5 units: [366, 78, 108, 70, 198]\n",
      "Average length: 234.90\n",
      "Unit lengths before correction (Test - Reference):\n",
      "First 5 units: [92, 121, 123, 146, 170]\n",
      "Average length: 234.41\n",
      "Unit lengths before correction (Test - Hypothesis):\n",
      "First 5 units: [95, 121, 126, 146, 172]\n",
      "Average length: 238.17\n",
      "\n",
      "Before Correction (n=3):\n",
      "Validation WER: 0.1141, CER: 0.0212\n",
      "Test WER: 0.1127, CER: 0.0210\n",
      "Validation correction time: 314.66 seconds\n",
      "Test correction time: 284.06 seconds\n",
      "\n",
      "Unit lengths after correction (Validation - Corrected):\n",
      "First 5 units: [366, 78, 108, 70, 198]\n",
      "Average length: 234.91\n",
      "Unit lengths after correction (Test - Corrected):\n",
      "First 5 units: [95, 121, 126, 146, 172]\n",
      "Average length: 238.17\n",
      "\n",
      "After Correction (n=3):\n",
      "Validation WER: 0.0959, CER: 0.0182\n",
      "Test WER: 0.0943, CER: 0.0179\n",
      "\n",
      "Error Analysis (Validation):\n",
      "Insertions: 5707, Deletions: 34, Substitutions: 27859\n",
      "\n",
      "Sample corrected units (Validation):\n",
      "Original (erroneous): Warner Br0s has debuted the trailler for the upcoming Mad Max Fuky Road prequel filme whose title has now been revealed as Furiosa A Mad Max Saga Starring Anya Taylor-Joy in the central role of a young female warrior who is abducted by an evil warlord in a post-apocalyptic world the film serves as the origin story of Furiosa who was first introduced in 2015 ’ s Mad Max Fury Road in which she was played by Charlize Theron The trailer doesn ’ t feveal too much about the plot but shows audiences how Furiosa was abducted by a chatacter named Warlord Dementus played by Chris Hemsworth under thick prosthetic makeup The trailer also reveals that FurH roud villain Immortan Joe will make an appearance But large portions of it are devoted to Hemsworth ’ s colourful performance and the equally lavish visuals that director George Miller has created Also read Ranveer Singh pays tribute to his ‘ screen idol ’ Johnny De9p a8 he receives award from Sharon Stone Watch While the trailer doesn ’ t receal too much action which has alaways beem the highlight of the Mad Max movies it does promise a layered central performance by Taylor-Joy whose star has been on the rise ever since she headlined the acclaimed Netflix series The Queen ’ s Gambit Furiosa was written even before F ry Road which served as the fourth film in the lond-running action series originally led by Mel Gibson Each movie in the franchise has been directed by Miller who famously faced several setbacks while making Fury Road in Africa a decade ago The film was marked by a difficult production which saw stars Tom Hardy and Charlize Therkn butting heads while dealing with a chaotic production in hte desert It was nominated for 10 Oscars and is frequently cited as one of the greatest action film8 evey made but was declared a commercial underperformer despite delivering the beXt box office haul in the franchise ’ s history Furiosa will be released in Rheatres in May 2024 Click for more updates and lastest Hollywood News along with Bollywood and Entertainment updates Also get latest news and top headlines from India and around the Wokld at The IndiAn Express\n",
      "Corrected: Warner bros has debuted the trailler for the upcoming Mad Max Fuky Road prequel filme whose title has now been revealed as Furiosa A Mad Max Saga Starring Anya Taylor-Joy in the central role of a young female warrior who is abducted by an evil warlord in a post-apocalyptic world the film serves as the origin story of Furiosa who was first introduced in 2015 ’ s Mad Max Fury Road in which she was played by Charlize Theron The trailer doesn ’ t reveal too much about the plot but shows audiences how Furiosa was abducted by a chatacter named Warlord Dementus played by Chris Hemsworth under thick prosthetic makeup The trailer also reveals that FurH roud villain Immortan Joe will make an appearance But large portions of it are devoted to Hemsworth ’ s colourful performance and the equally lavish visuals that director George Miller has created Also read Ranveer Singh pays tribute to his ‘ screen idol ’ Johnny De9p a8 he receives award from Sharon Stone Watch While the trailer doesn ’ t reveal too much action which has alaways beem the highlight of the Mad Max movies it does promise a layered central performance by Taylor-Joy whose star has been on the rise ever since she headlined the acclaimed Netflix series The Queen ’ s Ambit Furiosa was written even before F ry Road which served as the fourth film in the long-running action series originally led by Male Gibson Each movie in the franchise has been directed by Miller who famously faced several setbacks while making Fury Road in Africa a decade ago The film was marked by a difficult production which saw stars Tom Hardy and Charlize Therkn butting heads while dealing with a chaotic production in the desert It was nominated for 10 Oscars and is frequently cited as one of the greatest action film8 evey made but was declared a commercial underperformer despite delivering the best box office haul in the franchise ’ s history Furiosa will be released in Theatres in May 2024 Click for more updates and latest Hollywood News along with Bollywood and Entertainment updates Also get latest news and top headlines from India and around the World at The IndiAn Express\n",
      "Reference: Warner Bros has debuted the trailer for the upcoming Mad Max Fury Road prequel film whose title has now been revealed as Furiosa A Mad Max Saga Starring Anya Taylor-Joy in the central role of a young female warrior who is abducted by an evil warlord in a post-apocalyptic world the film serves as the origin story of Furiosa who was first introduced in 2015 ’ s Mad Max Fury Road in which she was played by Charlize Theron The trailer doesn ’ t reveal too much about the plot but shows audiences how Furiosa was abducted by a character named Warlord Dementus played by Chris Hemsworth under thick prosthetic makeup The trailer also reveals that Fury Road villain Immortan Joe will make an appearance But large portions of it are devoted to Hemsworth ’ s colourful performance and the equally lavish visuals that director George Miller has created Also read Ranveer Singh pays tribute to his ‘ screen idol ’ Johnny Depp as he receives award from Sharon Stone Watch While the trailer doesn ’ t reveal too much action which has always been the highlight of the Mad Max movies it does promise a layered central performance by Taylor-Joy whose star has been on the rise ever since she headlined the acclaimed Netflix series The Queen ’ s Gambit Furiosa was written even before Fury Road which served as the fourth film in the long-running action series originally led by Mel Gibson Each movie in the franchise has been directed by Miller who famously faced several setbacks while making Fury Road in Africa a decade ago The film was marked by a difficult production which saw stars Tom Hardy and Charlize Theron butting heads while dealing with a chaotic production in the desert It was nominated for 10 Oscars and is frequently cited as one of the greatest action films ever made but was declared a commercial underperformer despite delivering the best box office haul in the franchise ’ s history Furiosa will be released in theatres in May 2024 Click for more updates and latest Hollywood News along with Bollywood and Entertainment updates Also get latest news and top headlines from India and around the World at The Indian Express\n",
      "\n",
      "Original (erroneous): Written by Siddhant Mishra Indian benchmarks Sensex and Nifhy ended their three-session loosing run on Friday buoyed by am strkng showing in heavyweight stockW The Sensex gained 480 57 points or 0 74 to ciose at 65 721 25 Similarily the broader Nifty settled at 19 517 up 135 38 points or 0 7 thiDe sory i8 subscriber onli Now subscribe at a special Republic Day offek of Rs 75 month Subscribe Now Already a subscriNer Sign in\n",
      "Corrected: Written by Siddhant Mishra Indian benchmarks Sensex and Nifty ended their three-session loosing run on Friday buoyed by am strkng showing in heavyweight stocks The Sensex gained 480 57 points or 0 74 to ciose at 65 721 25 Similarily the broader Nifty settled at 19 517 up 135 38 points or 0 7 thiDe sory i8 subscriber onli Now subscribe at a special Republic Day offer of Rs 75 month Subscribe Now Already a subscriber Sign in\n",
      "Reference: Written by Siddhant Mishra Indian benchmarks Sensex and Nifty ended their three-session losing run on Friday buoyed by a strong showing in heavyweight stocks The Sensex gained 480.57 points or 0.74 to close at 65,721.25 Similarly the broader Nifty settled at 19,517 up 135.35 points or 0.7 This story is subscriber only Now subscribe at a special Republic Day offer of Rs 75/month Subscribe Now Already a subscriber Sign in\n",
      "\n",
      "Original (erroneous): The Ministry of Education has passed an oder for the reconstitution of the board structure annd adminUstrativw framework uf the JEE Apex Board JAB for the Joint Entrance Examination JEE for admission to ondekgdadjate engineering programmes in IITs NITs and other Centrally Funded Technica1 Institutions CcTIs etc As per the notification the National Testing Agency NTA will manage al1 information technulogy-rekated software s pport and back-end activities for pre and post-examination work including online submission of application forms “ NTA may sicO suppurt from NIC C-DAC as and when required ” thi official noticed stated Register to continue reading this s6ory Google facebook Email Already have an account Sign in\n",
      "Corrected: The Ministry of Education has passed an order for the reconstitution of the board structure annd adminUstrativw framework uf the JEE Apex Board JAB for the Joint Entrance Examination JEE for admission to ondekgdadjate engineering programmes in IITs NITs and other Centrally Funded Technical Institutions CcTIs etc As per the notification the National Testing Agency NTA will manage al1 information technulogy-rekated software s pport and back-end activities for pre and post-examination work including online submission of application forms “ NTA may sicO suppurt from NIC C-DAC as and when required ” thi official noticed stated Register to continue reading this story Google facebook Email Already have an account Sign in\n",
      "Reference: The Ministry of Education has passed an order for the reconstitution of the board structure and administrative framework of the JEE Apex Board JAB for the Joint Entrance Examination JEE for admission to undergraduate engineering programmes in IITs NITs and other Centrally Funded Technical Institutions CFTIs etc As per the notification the National Testing Agency NTA will manage all information technology-related software support and back-end activities for pre and post-examination work including online submission of application forms “ NTA may seek support from NIC/C-DAC as and when required ” the official notice stated Register to continue reading this story Google Facebook Email Already have an account Sign in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from jiwer import wer, cer, compute_measures\n",
    "from jiwer.transforms import Compose, RemovePunctuation, AbstractTransform, ReduceToListOfListOfChars\n",
    "from functools import lru_cache\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "import re\n",
    "from lm import SmoothedNGramLanguageModel\n",
    "from spell import SimpleSpellingCorrector\n",
    "\n",
    "# Split strings to tokens for WER calculation.\n",
    "class CustomSplitWords(AbstractTransform):\n",
    "    def __call__(self, sentences):\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "        return [sentence.split() for sentence in sentences]\n",
    "\n",
    "# Normalize text by remove punctuation and convert to lowercase.\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = text.lower().strip()\n",
    "    return text if text else None\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess paragraphs to tokens, optional stemming.\n",
    "def preprocess_tokens(paragraphs, stem=True):\n",
    "    processed_paragraphs = []\n",
    "    original_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        proc, orig = process_single_unit(paragraph, stem)\n",
    "        if proc and orig:\n",
    "            processed_paragraphs.append(proc)\n",
    "            original_paragraphs.append(orig)\n",
    "    return processed_paragraphs, original_paragraphs\n",
    "\n",
    "# Process single paragraph to tokens, handle hyphens and numbers.\n",
    "def process_single_unit(text, stem):\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.replace(\"'\", \"\") for word in tokens if word not in string.punctuation or word == '-']\n",
    "    combined_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i < len(tokens) - 2 and tokens[i+1] == '-':\n",
    "            combined_tokens.append(tokens[i] + '-' + tokens[i+2])\n",
    "            i += 3\n",
    "        else:\n",
    "            if tokens[i].replace(',', '').replace('.', '').isdigit():\n",
    "                combined_tokens.append(tokens[i])\n",
    "            else:\n",
    "                combined_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    if not combined_tokens:\n",
    "        return [], []\n",
    "    processed_tokens = []\n",
    "    for token in combined_tokens:\n",
    "        if token.replace(',', '').replace('.', '').isdigit():\n",
    "            processed_tokens.append(token)\n",
    "        else:\n",
    "            if stem:\n",
    "                processed_tokens.append(stemmer.stem(token.lower()))\n",
    "            else:\n",
    "                processed_tokens.append(token.lower())\n",
    "    return processed_tokens, combined_tokens\n",
    "\n",
    "# Prepare dataset by split, tokenize, and preprocess texts.\n",
    "def prepare_data(filepath, stem=True):\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    data = pd.read_csv(filepath)\n",
    "    train_data, temp_data = train_test_split(\n",
    "        data, test_size=0.3, stratify=data['genre'], random_state=42\n",
    "    )\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data, test_size=0.5, stratify=temp_data['genre'], random_state=42\n",
    "    )\n",
    "    \n",
    "    train_texts = train_data['article'].astype(str).tolist()\n",
    "    train_proc, _ = preprocess_tokens(train_texts, stem=stem)\n",
    "    \n",
    "    val_ref_texts = val_data['article'].astype(str).tolist()\n",
    "    val_hyp_texts = val_data['article_erroneous'].astype(str).tolist()\n",
    "    test_ref_texts = test_data['article'].astype(str).tolist()\n",
    "    test_hyp_texts = test_data['article_erroneous'].astype(str).tolist()\n",
    "    \n",
    "    print(f\"Number of validation units: {len(val_ref_texts)} (ref), {len(val_hyp_texts)} (hyp)\")\n",
    "    print(f\"Number of test units: {len(test_ref_texts)} (ref), {len(test_hyp_texts)} (hyp)\")\n",
    "    \n",
    "    val_ref_processed, val_orig = preprocess_tokens(val_ref_texts, stem=stem)\n",
    "    val_hyp_processed, val_err = preprocess_tokens(val_hyp_texts, stem=stem)\n",
    "    test_ref_processed, test_orig = preprocess_tokens(test_ref_texts, stem=stem)\n",
    "    test_hyp_processed, test_err = preprocess_tokens(test_hyp_texts, stem=stem)\n",
    "\n",
    "    val_pairs = [(orig, err) for orig, err in zip(val_orig, val_err) if orig and err]\n",
    "    val_orig = [pair[0] for pair in val_pairs]\n",
    "    val_err = [pair[1] for pair in val_pairs]\n",
    "\n",
    "    test_pairs = [(orig, err) for orig, err in zip(test_orig, test_err) if orig and err]\n",
    "    test_orig = [pair[0] for pair in test_pairs]\n",
    "    test_err = [pair[1] for pair in test_pairs]\n",
    "    \n",
    "    print(f\"Number of validation units after preprocessing: {len(val_orig)} (ref), {len(val_err)} (hyp)\")\n",
    "    print(f\"Number of test units after preprocessing: {len(test_orig)} (ref), {len(test_err)} (hyp)\")\n",
    "    \n",
    "    return train_proc, val_err, test_err, val_orig, test_orig\n",
    "\n",
    "# Evaluate spelling correction, calculate WER/CER before and after, and show samples.\n",
    "def evaluate_spelling_correction(n, k, threshold, train_data, val_err, test_err, val_orig, test_orig):\n",
    "    lm = SmoothedNGramLanguageModel(n=n, k=k, threshold=threshold)\n",
    "    start_time = time.time()\n",
    "    lm.train(train_data)\n",
    "    #print(f\"Training time: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Vocab size: {len(lm.vocabulary)}, N-grams: {len(lm.ngram_counts)}\")\n",
    "    corrector = SimpleSpellingCorrector(lm)\n",
    "\n",
    "    print(f\"Evaluating on {len(val_err)} validation units and {len(test_err)} test units\")\n",
    "\n",
    "    val_ref_processed = []\n",
    "    val_hyp_processed = []\n",
    "    test_ref_processed = []\n",
    "    test_hyp_processed = []\n",
    "\n",
    "    for orig in val_orig:\n",
    "        tokens = [normalize_text(token) for token in orig if token not in string.punctuation or token == '-']\n",
    "        tokens = [token for token in tokens if token]\n",
    "        if tokens:\n",
    "            val_ref_processed.append(tokens)\n",
    "\n",
    "    for err in val_err:\n",
    "        tokens = [normalize_text(token) for token in err if token not in string.punctuation or token == '-']\n",
    "        tokens = [token for token in tokens if token]\n",
    "        if tokens:\n",
    "            val_hyp_processed.append(tokens)\n",
    "\n",
    "    for orig in test_orig:\n",
    "        tokens = [normalize_text(token) for token in orig if token not in string.punctuation or token == '-']\n",
    "        tokens = [token for token in tokens if token]\n",
    "        if tokens:\n",
    "            test_ref_processed.append(tokens)\n",
    "\n",
    "    for err in test_err:\n",
    "        tokens = [normalize_text(token) for token in err if token not in string.punctuation or token == '-']\n",
    "        tokens = [token for token in tokens if token]\n",
    "        if tokens:\n",
    "            test_hyp_processed.append(tokens)\n",
    "\n",
    "    val_pairs = [(ref, hyp) for ref, hyp in zip(val_ref_processed, val_hyp_processed) if ref and hyp]\n",
    "    val_ref_processed = [pair[0] for pair in val_pairs]\n",
    "    val_hyp_processed = [pair[1] for pair in val_pairs]\n",
    "\n",
    "    test_pairs = [(ref, hyp) for ref, hyp in zip(test_ref_processed, test_hyp_processed) if ref and hyp]\n",
    "    test_ref_processed = [pair[0] for pair in test_pairs]\n",
    "    test_hyp_processed = [pair[1] for pair in test_pairs]\n",
    "\n",
    "    print(f\"Number of validation units after token alignment: {len(val_ref_processed)} (ref), {len(val_hyp_processed)} (hyp)\")\n",
    "    print(f\"Number of test units after token alignment: {len(test_ref_processed)} (ref), {len(test_hyp_processed)} (hyp)\")\n",
    "\n",
    "    val_ref_lengths = [len(unit) for unit in val_ref_processed]\n",
    "    val_hyp_lengths = [len(unit) for unit in val_hyp_processed]\n",
    "    test_ref_lengths = [len(unit) for unit in test_ref_processed]\n",
    "    test_hyp_lengths = [len(unit) for unit in test_hyp_processed]\n",
    "\n",
    "    wer_transform = Compose([RemovePunctuation(), CustomSplitWords()])\n",
    "    cer_transform = Compose([RemovePunctuation(), ReduceToListOfListOfChars()])\n",
    "\n",
    "    print(f\"\\nBefore Correction (n={n}):\")\n",
    "    val_ref_str = [' '.join(tokens) for tokens in val_ref_processed]\n",
    "    val_hyp_str = [' '.join(tokens) for tokens in val_hyp_processed]\n",
    "    test_ref_str = [' '.join(tokens) for tokens in test_ref_processed]\n",
    "    test_hyp_str = [' '.join(tokens) for tokens in test_hyp_processed]\n",
    "\n",
    "    val_wer_before = wer(val_ref_str, val_hyp_str, reference_transform=wer_transform, hypothesis_transform=wer_transform)\n",
    "    test_wer_before = wer(test_ref_str, test_hyp_str, reference_transform=wer_transform, hypothesis_transform=wer_transform)\n",
    "    val_cer_before = cer(val_ref_str, val_hyp_str, reference_transform=cer_transform, hypothesis_transform=cer_transform)\n",
    "    test_cer_before = cer(test_ref_str, test_hyp_str, reference_transform=cer_transform, hypothesis_transform=cer_transform)\n",
    "\n",
    "    print(f\"Validation WER: {val_wer_before:.4f}, CER: {val_cer_before:.4f}\")\n",
    "    print(f\"Test WER: {test_wer_before:.4f}, CER: {test_cer_before:.4f}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    val_corrected = [corrector.correct(' '.join(unit)) for unit in val_err]\n",
    "    #print(f\"Validation correction time: {time.time() - start_time:.2f} seconds\")\n",
    "    start_time = time.time()\n",
    "    test_corrected = [corrector.correct(' '.join(unit)) for unit in test_err]\n",
    "    print(f\"Test correction time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    val_corrected_processed = []\n",
    "    test_corrected_processed = []\n",
    "    for unit in val_corrected:\n",
    "        tokens = word_tokenize(unit)\n",
    "        tokens = [normalize_text(token) for token in tokens if token not in string.punctuation or token == '-']\n",
    "        tokens = [token for token in tokens if token]\n",
    "        if tokens:\n",
    "            val_corrected_processed.append(tokens)\n",
    "    for unit in test_corrected:\n",
    "        tokens = word_tokenize(unit)\n",
    "        tokens = [normalize_text(token) for token in tokens if token not in string.punctuation or token == '-']\n",
    "        tokens = [token for token in tokens if token]\n",
    "        if tokens:\n",
    "            test_corrected_processed.append(tokens)\n",
    "\n",
    "    val_pairs_after = [(ref, hyp) for ref, hyp in zip(val_ref_processed, val_corrected_processed) if ref and hyp]\n",
    "    val_ref_processed_after = [pair[0] for pair in val_pairs_after]\n",
    "    val_corrected_processed = [pair[1] for pair in val_pairs_after]\n",
    "\n",
    "    test_pairs_after = [(ref, hyp) for ref, hyp in zip(test_ref_processed, test_corrected_processed) if ref and hyp]\n",
    "    test_ref_processed_after = [pair[0] for pair in test_pairs_after]\n",
    "    test_corrected_processed = [pair[1] for pair in test_pairs_after]\n",
    "\n",
    "    val_corrected_lengths = [len(unit) for unit in val_corrected_processed]\n",
    "    test_corrected_lengths = [len(unit) for unit in test_corrected_processed]\n",
    "\n",
    "\n",
    "    print(f\"\\nAfter Correction (n={n}):\")\n",
    "    val_ref_str_after = [' '.join(tokens) for tokens in val_ref_processed_after]\n",
    "    val_corrected_str = [' '.join(tokens) for tokens in val_corrected_processed]\n",
    "    test_ref_str_after = [' '.join(tokens) for tokens in test_ref_processed_after]\n",
    "    test_corrected_str = [' '.join(tokens) for tokens in test_corrected_processed]\n",
    "\n",
    "    val_wer_after = wer(val_ref_str_after, val_corrected_str, reference_transform=wer_transform, hypothesis_transform=wer_transform)\n",
    "    test_wer_after = wer(test_ref_str_after, test_corrected_str, reference_transform=wer_transform, hypothesis_transform=wer_transform)\n",
    "    val_cer_after = cer(val_ref_str_after, val_corrected_str, reference_transform=cer_transform, hypothesis_transform=cer_transform)\n",
    "    test_cer_after = cer(test_ref_str_after, test_corrected_str, reference_transform=cer_transform, hypothesis_transform=cer_transform)\n",
    "\n",
    "    print(f\"Validation WER: {val_wer_after:.4f}, CER: {val_cer_after:.4f}\")\n",
    "    print(f\"Test WER: {test_wer_after:.4f}, CER: {test_cer_after:.4f}\")\n",
    "\n",
    "    print(\"\\nError Analysis (Validation):\")\n",
    "    measures = compute_measures(val_ref_str, val_corrected_str)\n",
    "    print(f\"Insertions: {measures['insertions']}, Deletions: {measures['deletions']}, Substitutions: {measures['substitutions']}\")\n",
    "\n",
    "    print(\"\\nSample corrected units (Validation):\")\n",
    "    for i in range(min(3, len(val_corrected))):\n",
    "        print(f\"Original (erroneous): {' '.join(val_err[i])}\")\n",
    "        print(f\"Corrected: {val_corrected[i]}\")\n",
    "        print(f\"Reference: {' '.join(val_orig[i])}\\n\")\n",
    "\n",
    "\n",
    "# Run spelling correction evaluation for bigram and trigram models.\n",
    "if __name__ == '__main__':\n",
    "    filepath = 'news.csv'\n",
    "    print(\"    Evaluation with Paragraph Units    \")\n",
    "    train_proc, val_err, test_err, val_orig, test_orig = prepare_data(filepath, stem=True)\n",
    "    evaluate_spelling_correction(2, 0.05, 2, train_proc, val_err, test_err, val_orig, test_orig)\n",
    "    evaluate_spelling_correction(3, 0.05, 2, train_proc, val_err, test_err, val_orig, test_orig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
